{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Final Verison\n",
        "# Used 10min2s to retrieve Jan to May (5 months) data\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "def get_url(soup):\n",
        "  div_tags = soup.find_all(\"div\", class_=\"item\")\n",
        "  links = []\n",
        "  for div_tag in div_tags:\n",
        "    span_tag = div_tag.find(\"span\", class_=\"title\")\n",
        "    link = span_tag.find(\"a\")[\"href\"]\n",
        "    links.append(link)\n",
        "  basic_url= \"https://news.rthk.hk\" #Combine the links together\n",
        "  target_url=[]\n",
        "  for target_link in links:\n",
        "    target_url.append(basic_url+target_link)\n",
        "  return target_url\n",
        "def news_extract(target_url):\n",
        "  news_df = pd.DataFrame(columns=['Title', 'Content',\"Date\"])\n",
        "  news_response= requests.get(target_url)\n",
        "  news_soup = BeautifulSoup(news_response.content, \"html.parser\")\n",
        "  news_title= news_soup.find(\"h2\", class_=\"itemTitle\").text.strip()\n",
        "  news_content= news_soup.find(\"div\",class_=\"itemFullText\").text.strip()\n",
        "  news_date= news_soup.find(\"div\",class_=\"createddate\").text.strip()\n",
        "  news_row= pd.DataFrame({\"Title\":[news_title],\"Content\":[news_content],\"Date\":[news_date]})\n",
        "  news_df= pd.concat([news_df,news_row], ignore_index=True)\n",
        "  return news_df\n",
        "def check_empty(soup):\n",
        "  content = False\n",
        "  check_content= \"There is no News according to your request.\"\n",
        "  div_tags = soup.find_all(\"div\", class_=\"item\")\n",
        "  for div_tag in div_tags:\n",
        "    span_tag = div_tag.find(\"span\")\n",
        "    if span_tag.text == check_content:\n",
        "        content = False\n",
        "    else:\n",
        "        content= True\n",
        "        break\n",
        "  return content\n",
        "year=2022 # Modify Time\n",
        "# month=5\n",
        "# day=31\n",
        "for month in range(8,13):\n",
        "  news_file = pd.DataFrame(columns=['Title', 'Content',\"Date\"])\n",
        "  for day in range(1,31):\n",
        "    archive_url= f\"https://news.rthk.hk/rthk/en/news-archive.htm?archive_year={year}&archive_month=0{month}&archive_day={day}&archive_cat=12\" # archive_cat=12-> finance\n",
        "    session= requests.session()\n",
        "    response=session.get(archive_url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    if check_empty(soup)== False:\n",
        "      pass\n",
        "    else:\n",
        "      for news_url in get_url(soup):\n",
        "        news_file = pd.concat([news_file,news_extract(news_url)],ignore_index=True)\n",
        "  news_file.to_csv(f\"{year}{month:02d}Financial News from RTHK.csv\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "urU6urL94tsi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}